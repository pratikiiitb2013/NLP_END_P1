{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END_Assignment7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzldE0BNRACe4XitRWFZ43",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikiiitb2013/NLP_END_P1/blob/main/Session7/END_Assignment7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjOYxhhw2KzN"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HllAkm5M2I4K",
        "outputId": "a0cbbcab-131e-438a-fd62-01bfc74dd40a"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "pd.set_option('max_colwidth', 10000)\r\n",
        "\r\n",
        "import random\r\n",
        "import torch, torchtext\r\n",
        "from torchtext import data \r\n",
        "\r\n",
        "# Manual Seed\r\n",
        "SEED = 43\r\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbf9a943b58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbZZaf5IwIx9"
      },
      "source": [
        "# Downloading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-zcCEPcyto",
        "outputId": "a190f7b1-9153-453f-c84e-27ec1352a28a"
      },
      "source": [
        "!wget -O stanford_sentiment_treebank.zip http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\r\n",
        "!unzip stanford_sentiment_treebank.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-08 17:28:04--  http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip [following]\n",
            "--2021-01-08 17:28:04--  https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6372817 (6.1M) [application/zip]\n",
            "Saving to: ‘stanford_sentiment_treebank.zip’\n",
            "\n",
            "stanford_sentiment_ 100%[===================>]   6.08M  3.75MB/s    in 1.6s    \n",
            "\n",
            "2021-01-08 17:28:06 (3.75 MB/s) - ‘stanford_sentiment_treebank.zip’ saved [6372817/6372817]\n",
            "\n",
            "Archive:  stanford_sentiment_treebank.zip\n",
            "   creating: stanfordSentimentTreebank/\n",
            "  inflating: stanfordSentimentTreebank/datasetSentences.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/stanfordSentimentTreebank/\n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSentences.txt  \n",
            "  inflating: stanfordSentimentTreebank/datasetSplit.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSplit.txt  \n",
            "  inflating: stanfordSentimentTreebank/dictionary.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._dictionary.txt  \n",
            "  inflating: stanfordSentimentTreebank/original_rt_snippets.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._original_rt_snippets.txt  \n",
            "  inflating: stanfordSentimentTreebank/README.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._README.txt  \n",
            "  inflating: stanfordSentimentTreebank/sentiment_labels.txt  \n",
            "  inflating: __MACOSX/stanfordSentimentTreebank/._sentiment_labels.txt  \n",
            "  inflating: stanfordSentimentTreebank/SOStr.txt  \n",
            "  inflating: stanfordSentimentTreebank/STree.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsgAUBiD1PzH"
      },
      "source": [
        "# Preprocessing datasets to get sentences and lables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_i6H1ZqrjRx"
      },
      "source": [
        "datasetSentences_df = pd.read_csv(\"/content/stanfordSentimentTreebank/datasetSentences.txt\", sep=\"\\t\")\r\n",
        "dictionary_df = pd.read_csv(\"/content/stanfordSentimentTreebank/dictionary.txt\", sep=\"|\", names=[\"Phrase\", \"Phrase_Id\"])\r\n",
        "sentiment_labels_df =  pd.read_csv(\"/content/stanfordSentimentTreebank/sentiment_labels.txt\", sep=\"|\")\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqWaZlDnsaOs"
      },
      "source": [
        "full_df = datasetSentences_df.merge(\r\n",
        "    dictionary_df, how = 'inner', left_on='sentence', right_on='Phrase'\r\n",
        "    ).merge(\r\n",
        "        sentiment_labels_df, how = 'inner', left_on = 'Phrase_Id', right_on = 'phrase ids')\r\n",
        "full_df = full_df[['sentence_index','sentence','sentiment values']]\r\n",
        "full_df.rename(columns={'sentiment values': 'sentiment_value'}, inplace=True)\r\n",
        "\r\n",
        "full_df[\"sentence\"] = full_df[\"sentence\"].str.replace(\".\",\"\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "J_dqapwruup3",
        "outputId": "9d7cee2d-86cc-40ec-f889-88305468467f"
      },
      "source": [
        "print(full_df.shape) ## 11286\r\n",
        "full_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11286, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of JRR Tolkien 's Middle-earth</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to have fun , Wasabi is a good place to start</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... sentiment_value\n",
              "0               1  ...         0.69444\n",
              "1               2  ...         0.83333\n",
              "2               3  ...         0.51389\n",
              "3               4  ...         0.73611\n",
              "4               5  ...         0.86111\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8dwqfK_DuyW5",
        "outputId": "24326709-eff0-493d-f5f3-c596c05b6351"
      },
      "source": [
        "full_df.sentiment_value.hist(bins=10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbf4a5b8f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0KbEgom5tB4"
      },
      "source": [
        "# creating sentiment label based on value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "p-WY2w3H3Sfz",
        "outputId": "5704a101-6019-4eff-c3a4-f42624f3d76b"
      },
      "source": [
        "## negative - <=0.4\r\n",
        "## positive - >=0.6\r\n",
        "## neutral - between 0.4 to 0.6\r\n",
        "\r\n",
        "full_df['label'] = np.where(full_df['sentiment_value'] < 0.4, 'negative', \r\n",
        "                              (np.where(full_df['sentiment_value'] > 0.6, 'positive', 'neutral')))\r\n",
        "full_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal</td>\n",
              "      <td>0.69444</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of JRR Tolkien 's Middle-earth</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>0.51389</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to have fun , Wasabi is a good place to start</td>\n",
              "      <td>0.73611</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie that 's so honest and keenly observed that it does n't feel like one</td>\n",
              "      <td>0.86111</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ...     label\n",
              "0               1  ...  positive\n",
              "1               2  ...  positive\n",
              "2               3  ...   neutral\n",
              "3               4  ...  positive\n",
              "4               5  ...  positive\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZHN80pP8jHT"
      },
      "source": [
        "# Dividing into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0lHH6Vi7wgA",
        "outputId": "fc9bd19a-2bff-4532-b06b-4f78d04fbcdb"
      },
      "source": [
        "train_df = full_df.sample(frac = 0.7, random_state=43) \r\n",
        "test_df = full_df[~full_df.sentence_index.isin(train_df.sentence_index)]\r\n",
        "print(full_df.shape, train_df.shape, test_df.shape)\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11286, 4) (7900, 4) (3386, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ16vwAuASfg"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "e_KQ_C3m85fU",
        "outputId": "dcb7eada-b769-4320-9d5b-3f13dd922aa2"
      },
      "source": [
        "## We will use 3 methods for augmentation - random delete, random swap and back translate\r\n",
        "## we will randomly pick some sentences which are long enogh and apply these augmentations\r\n",
        "## we will then append the augmented data to the origina training data\r\n",
        "\r\n",
        "\r\n",
        "train_df['words'] = train_df['sentence'].str.split().apply(len)\r\n",
        "train_df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "      <th>label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8175</th>\n",
              "      <td>8562</td>\n",
              "      <td>There 's an audience for it , but it could have been funnier and more innocent</td>\n",
              "      <td>0.38889</td>\n",
              "      <td>negative</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1430</th>\n",
              "      <td>1489</td>\n",
              "      <td>For those who pride themselves on sophisticated , discerning taste , this might not seem like the proper cup of tea , however it is almost guaranteed that even the stuffiest cinema goers will laugh their \\*\\*\\* off for an hour-and-a-half</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>positive</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4286</th>\n",
              "      <td>4481</td>\n",
              "      <td>A gripping documentary that reveals how deep the antagonism lies in war-torn Jerusalem</td>\n",
              "      <td>0.63889</td>\n",
              "      <td>positive</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4367</th>\n",
              "      <td>4566</td>\n",
              "      <td>Those moviegoers who would automatically bypass a hip-hop documentary should give `` Scratch '' a second look</td>\n",
              "      <td>0.81944</td>\n",
              "      <td>positive</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5498</th>\n",
              "      <td>5750</td>\n",
              "      <td>The characters are never more than sketches  which leaves any true emotional connection or identification frustratingly out of reach</td>\n",
              "      <td>0.12500</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... words\n",
              "8175            8562  ...    16\n",
              "1430            1489  ...    41\n",
              "4286            4481  ...    13\n",
              "4367            4566  ...    17\n",
              "5498            5750  ...    19\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNMstGw7-kL0"
      },
      "source": [
        "def random_deletion(words, p=0.5):\r\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \r\n",
        "    if len(remaining) == 0:\r\n",
        "        return [random.choice(words)] \r\n",
        "    else:\r\n",
        "        return remaining"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCt6IzXOALoR"
      },
      "source": [
        "def random_swap(sentence, n=5): \r\n",
        "    length = range(len(sentence)) \r\n",
        "    for _ in range(n):\r\n",
        "        idx1, idx2 = random.sample(length, 2)\r\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \r\n",
        "    return sentence"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUkPMDMD0WCN",
        "outputId": "1e550714-0f7c-47c1-d07f-5b9c8915f57c"
      },
      "source": [
        "!pip3 install googletrans==3.1.0a0\r\n",
        "import random\r\n",
        "import googletrans\r\n",
        "from googletrans import Translator"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/78/be/7b8b99fd74ff5684225f50dd0e865393d2265656ef3b4ba9eaaaffe622b8/rfc3986-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 17.4MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
            "\u001b[?25hCollecting contextvars>=2.1; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 14.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: googletrans, contextvars\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp36-none-any.whl size=16368 sha256=56f95a67701213858eecf11ddbfcabf4e6a63b2f55dea154bbafe89a835c5e65\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7667 sha256=d93ae135344abe4dd663a017e131b559cf6959c88ae80b3c6b8e8e5c9d179e60\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built googletrans contextvars\n",
            "Installing collected packages: hyperframe, hpack, h2, immutables, contextvars, sniffio, h11, httpcore, rfc3986, hstspreload, httpx, googletrans\n",
            "Successfully installed contextvars-2.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 immutables-0.14 rfc3986-1.4.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FDEkAMu0YD4"
      },
      "source": [
        "def back_translate(sentence):\r\n",
        "  translator = Translator()\r\n",
        "  available_langs = list(googletrans.LANGUAGES.keys())\r\n",
        "  trans_lang = random.choice(available_langs)\r\n",
        "  print(googletrans.LANGUAGES[trans_lang])\r\n",
        "  translations = translator.translate(sentence, dest=trans_lang)\r\n",
        "  print(translations)\r\n",
        "  translations_en_random = translator.translate(translations.text, src=trans_lang, dest='en') \r\n",
        "  return translations_en_random.text\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0JVjI-29h-F",
        "outputId": "c91ff704-8ffd-4ef0-c558-94df60aaa7e9"
      },
      "source": [
        "print(train_df.shape)\r\n",
        "print(train_df[train_df.words>10].shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7900, 5)\n",
            "(6081, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFqqI0fP02wx",
        "outputId": "a97806d1-718b-4237-d614-6dfcb1c4d5c2"
      },
      "source": [
        "for_translate_df= train_df[train_df.words>10].sample(n=100,random_state=43)\r\n",
        "for_translate_df1 = for_translate_df.copy()\r\n",
        "for_translate_df1['sentence'] = for_translate_df1['sentence'].apply(back_translate)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hebrew\n",
            "Translated(src=en, dest=iw, text=לעתים קרובות זה משעשע בקלילות, אבל הבעיות של הדמויות אף פעם לא הופכות להיות חשובות לנו, והסיפור לעולם לא תופס, pronunciation=It 's often faintly amusing , but the problems of the characters never become important to us , and the story never takes hold , extra_data=\"{'translat...\")\n",
            "marathi\n",
            "Translated(src=en, dest=mr, text=अलिकडे आणि कोणतीही वास्तविक कच्ची भावना नसते, जी वैयक्तिक संबंधांवर अवलंबून असलेल्या चित्रपटासाठी घातक आहे, pronunciation=Alikaḍē āṇi kōṇatīhī vāstavika kaccī bhāvanā nasatē, jī vaiyaktika sambandhānvara avalambūna asalēlyā citrapaṭāsāṭhī ghātaka āhē, extra_data=\"{'translat...\")\n",
            "tamil\n",
            "Translated(src=en, dest=ta, text=இது 1967 ஐ 20 ஆம் நூற்றாண்டின் முக்கிய திருப்புமுனையாகக் கருதி, தெருக்களில் உள்ள அதிருப்தியாளர்களின் படங்களுக்கு மீண்டும் மீண்டும் திரும்பும்போது, ​​அது ஆபத்தான நடப்பு, pronunciation=Itu 1967 ai 20 ām nūṟṟāṇṭiṉ mukkiya tiruppumuṉaiyākak karuti, terukkaḷil uḷḷa atiruptiyāḷarkaḷiṉ paṭaṅkaḷukku mīṇṭum mīṇṭum tirumpumpōtu, ​​atu āpattāṉa naṭappu, extra_data=\"{'translat...\")\n",
            "pashto\n",
            "Translated(src=en, dest=ps, text=دا د حیرانتیا وړ شمیرې دي چې هولوکاسټ یې رامینځته کړی, pronunciation=It 's incredible the number of stories the Holocaust has generated , extra_data=\"{'translat...\")\n",
            "finnish\n",
            "Translated(src=en, dest=fi, text=Se on suurin osa asioista, joista Costner-elokuvat tunnetaan; sen pyhä, itsekäs ja niin innokas ansaitsemaan rakkautemme, että haluat lyödä sitä, pronunciation=[[]], extra_data=\"{'translat...\")\n",
            "malayalam\n",
            "Translated(src=en, dest=ml, text=ചലച്ചിത്ര പ്രവർത്തകരുടെ ഉദ്ദേശ്യത്തെ ആർക്കും സംശയിക്കാനാവില്ല, പക്ഷേ ഗൈസിന് ഇപ്പോഴും വിപരീത ഫലപ്രദമാണെന്ന് തോന്നുന്നു, pronunciation=calaccitra pravarttakaruṭe uddēśyatte ārkkuṁ sanśayikkānāvilla, pakṣē gaisin ippēāḻuṁ viparīta phalapradamāṇenn tēānnunnu, extra_data=\"{'translat...\")\n",
            "hungarian\n",
            "Translated(src=en, dest=hu, text=Más szavakkal, ez csak egy újabb sportdráma \\ / karaktertanulmány, pronunciation=In other words , it 's just another sports drama\\/character study , extra_data=\"{'translat...\")\n",
            "khmer\n",
            "Translated(src=en, dest=km, text=ហើយមេរៀន, នៅចុងបញ្ចប់, មិនមានអ្វីថ្មីទេ, pronunciation=haey merien,  now chongobanhchob,  min mean avei thmei te, extra_data=\"{'translat...\")\n",
            "icelandic\n",
            "Translated(src=en, dest=is, text=Framleiðendum Mothman Prophecies tekst að framleiða það mest ógnvekjandi af öllum kvikmyndum - miðlungs hryllingsmynd of slæm til að vera góð og of góð til að vera slæm, pronunciation=The makers of Mothman Prophecies succeed in producing that most frightening of all movies -- a mediocre horror film too bad to be good and too good to be bad , extra_data=\"{'translat...\")\n",
            "german\n",
            "Translated(src=en, dest=de, text=Der Film würde viel besser als Videoinstallation in einem Museum funktionieren, in dem die Zuschauer frei gehen könnten, pronunciation=The film would work much better as a video installation in a museum , where viewers would be free to leave , extra_data=\"{'translat...\")\n",
            "persian\n",
            "Translated(src=en, dest=fa, text=کمبود شخصیت فیلم در همه جنبه های آن نفوذ می کند - از فیلم تلویزیونی ، کودک تحت تأثیر ، گرفته تا بی احترامی ترین صحنه های میخانه ایرلند که تاکنون فیلمبرداری شده است., pronunciation=The film 's lack of personality permeates all its aspects -- from the TV movie-esque , affected child acting to the dullest Irish pub scenes ever filmed , extra_data=\"{'translat...\")\n",
            "hmong\n",
            "Translated(src=en, dest=hmn, text=Nrog cov cheesiest monsters no sab ntawm ntshai heev spoof, uas Lawv tsis yog, nws yog qhov ntau yuav ntxias pw tsaug zog tshaj ntshai, pronunciation=With the cheesiest monsters this side of a horror spoof , which They is n't , it is more likely to induce sleep than fright , extra_data=\"{'translat...\")\n",
            "slovenian\n",
            "Translated(src=en, dest=sl, text=Ena ne tako majhna težava pri Expecting je, da celotna vaja nima pravega smisla, pronunciation=The one not-so-small problem with Expecting is that the entire exercise has no real point , extra_data=\"{'translat...\")\n",
            "polish\n",
            "Translated(src=en, dest=pl, text=W porównaniu z jego wcześniejszymi filmami wydaje się rozczarowująco cienki kawałek londyńskiego życia niższej klasy; mimo tytułu jest zaskakująco mało, pronunciation=[[]], extra_data=\"{'translat...\")\n",
            "scots gaelic\n",
            "Translated(src=en, dest=gd, text=Chan eil buaidh sam bith aige air na Kurds, ach chuir e sìos mi, pronunciation=It has no affect on the Kurds , but it wore me down , extra_data=\"{'translat...\")\n",
            "lithuanian\n",
            "Translated(src=en, dest=lt, text=simpatiškas dėl savo vaidmens, virtuvės ir keistų melodijų, pronunciation=likeable thanks to its cast , its cuisine and its quirky tunes , extra_data=\"{'translat...\")\n",
            "yiddish\n",
            "Translated(src=en, dest=yi, text=סקרינרייטערז סקאַט אַבאַט און מיכאל פּעטראָני האָבן פארקערט רייס ס קאָמפּלעקס אַקאַשאַ אין אַ קאַרטון פאַרזעעניש, pronunciation=skrinreyterz skat abat aun mikhal petroni hobn farkert reys s komplex akasha in a kartun farzeenish, extra_data=\"{'translat...\")\n",
            "corsican\n",
            "Translated(src=en, dest=co, text=Presenta una astuta valutazione di u torpore musicale di l'America Centrale è di a lotta disperata per fughje lu, pronunciation=Presents an astute appraisal of Middle American musical torpor and the desperate struggle to escape it , extra_data=\"{'translat...\")\n",
            "italian\n",
            "Translated(src=en, dest=it, text=Un thriller cupo e noioso con una ripresa d'addio che fallisce, pronunciation=A dark , dull thriller with a parting shot that misfires , extra_data=\"{'translat...\")\n",
            "hebrew\n",
            "Translated(src=en, dest=iw, text=היא מצליחה לדחוף את כשרונה המפתיע של אנג'לינה ג'ולי לקומדיה משפילה את עצמה, pronunciation=It manages to squeeze by on Angelina Jolie 's surprising flair for self-deprecating comedy , extra_data=\"{'translat...\")\n",
            "greek\n",
            "Translated(src=en, dest=el, text=Αυτό δεν είναι μια στάση και ευθυμία. είναι καθιστικό και συλλογιστείτε, pronunciation=[[]], extra_data=\"{'translat...\")\n",
            "chinese (simplified)\n",
            "Translated(src=en, dest=zh-cn, text=尽管埃斯特拉·布拉沃（Esela Bravo）的纪录片在古巴领导人菲德尔·卡斯特罗（Fidel Castro）的肖像中是不拘一格的，但仍然值得欣赏, pronunciation=Jǐnguǎn āi sī tè lā·bù lā wò (Esela Bravo) de jìlùpiàn zài gǔbā lǐngdǎo rén fēi dé'ěr·kǎ sī tè luō (Fidel Castro) de xiàoxiàng zhōng shì bùjū yī gé de, dàn réngrán zhídé xīnshǎng, extra_data=\"{'translat...\")\n",
            "korean\n",
            "Translated(src=en, dest=ko, text=세 개의 고리로 된 서커스처럼, 많은 부담이 있습니다., pronunciation=se gaeui golilo doen seokeoseucheoleom, manh-eun budam-i issseubnida., extra_data=\"{'translat...\")\n",
            "corsican\n",
            "Translated(src=en, dest=co, text=Per un filmu nantu à l'azzione, Ultimate X hè u filmu di schermu gigante più gabbiest di sempre, impastughjatu in una piena di hype, pronunciation=For a film about action , Ultimate X is the gabbiest giant-screen movie ever , bogging down in a barrage of hype , extra_data=\"{'translat...\")\n",
            "spanish\n",
            "Translated(src=en, dest=es, text=Lento y pesado, pero el drama de Rohmer se convierte en un intenso drama interior sobre la compasión, el sacrificio y el amor cristiano frente a la corrupción política., pronunciation=Slow and ponderous , but Rohmer 's drama builds to an intense indoor drama about compassion , sacrifice , and Christian love in the face of political corruption , extra_data=\"{'translat...\")\n",
            "yiddish\n",
            "Translated(src=en, dest=yi, text=שטייט ווי אַ דאָקומענט פון וואָס עס פּעלץ ווי אַ ניו יאָרקער - אָדער טאַקע אַ מענטש - אין די וואָכן נאָך 9 \\ / 11, pronunciation=shteyt vi a dokument fun vos es pelts vi a niu yorker - oder take a mentsh - in di vokhn nokh 9 \\ / 11, extra_data=\"{'translat...\")\n",
            "tajik\n",
            "Translated(src=en, dest=tg, text=Тавре ки ин қадар филмҳои тиҷории ба ҳадди аксар маҳдуди ин намуд ба назар мерасанд, вақти зиёдтар барои ҷалби гурӯҳҳои мувофиқ барои рӯйхати навозиш ва либоспӯшии ситорагон назар ба сценария, ки чанд шӯхии оқилона дорад ва на хеле дигар, pronunciation=[[]], extra_data=\"{'translat...\")\n",
            "javanese\n",
            "Translated(src=en, dest=jw, text=Pungkasane, sampeyan ora bisa ngrewangi rumangsa \"kesusu\", pronunciation=By the end you ca n't help but feel ` stoked  ', extra_data=\"{'translat...\")\n",
            "hausa\n",
            "Translated(src=en, dest=ha, text=Muccino da alama yana bincika ra'ayin me ya sa ɗan adam ke son abin da ba shi da shi, da kuma yadda wannan ya jefa mu cikin matsala, pronunciation=Muccino seems to be exploring the idea of why human beings long for what they do n't have , and how this gets us in trouble , extra_data=\"{'translat...\")\n",
            "javanese\n",
            "Translated(src=en, dest=jw, text=Film kasebut, kaya Bartleby, kalebu kaku - komedi kantor ekstra garing sing katon kaping pindho suwene 83 menit, pronunciation=The movie , like Bartleby , is something of a stiff -- an extra-dry office comedy that seems twice as long as its 83 minutes , extra_data=\"{'translat...\")\n",
            "yiddish\n",
            "Translated(src=en, dest=yi, text=קיסינג דזשעסיקאַ סטיין איז פריילעך אָדער גלייך, איינער פון די גרעסטע קינאָ אין טאָג, pronunciation=kising jesika steyn iz freylekh oder gleykh, eyner fun di greste kino in tog, extra_data=\"{'translat...\")\n",
            "spanish\n",
            "Translated(src=en, dest=es, text=Una secuela razonablemente entretenida del éxito familiar sorpresa de 1994 que puede afectar la credibilidad de los adultos, pronunciation=A reasonably entertaining sequel to 1994 's surprise family hit that may strain adult credibility , extra_data=\"{'translat...\")\n",
            "indonesian\n",
            "Translated(src=en, dest=id, text=Sweet Home Alabama adalah salah satu film bodoh, tetapi kebodohannya begitu tanpa henti tidak berbahaya sehingga hampir memenangkan Anda pada akhirnya, pronunciation=Sweet Home Alabama is one dumb movie , but its stupidity is so relentlessly harmless that it almost wins you over in the end , extra_data=\"{'translat...\")\n",
            "marathi\n",
            "Translated(src=en, dest=mr, text=जर आपण हा चित्रपट अलीकडे पाहिला नसेल तर स्पीलबर्गच्या कामातील विविध स्वरांबद्दल आपल्याला आश्चर्य वाटेल, pronunciation=Jara āpaṇa hā citrapaṭa alīkaḍē pāhilā nasēla tara spīlabargacyā kāmātīla vividha svarāmbaddala āpalyālā āścarya vāṭēla, extra_data=\"{'translat...\")\n",
            "galician\n",
            "Translated(src=en, dest=gl, text=Toma un personaxe que non nos gusta e outro que non cremos e ponse nunha batalla de vontades imposible de coidar e que non é moi divertida, pronunciation=Takes one character we do n't like and another we do n't believe , and puts them into a battle of wills that is impossible to care about and is n't very funny , extra_data=\"{'translat...\")\n",
            "telugu\n",
            "Translated(src=en, dest=te, text=గై రిట్చీ యొక్క లాక్, స్టాక్ మరియు టూ స్మోకింగ్ బారెల్స్ మరియు స్నాచ్ లలో నోటీసు పొందిన సమిష్టి ఆటగాడికి బాడ్ ఉన్నప్పటికీ, అతను తన మొదటి నటించిన వాహనం ఆధారంగా ఇంటి పేరుగా మారే అవకాశం లేదు., pronunciation=Gai riṭcī yokka lāk, sṭāk mariyu ṭū smōkiṅg bārels mariyu snāc lalō nōṭīsu pondina samiṣṭi āṭagāḍiki bāḍ unnappaṭikī, atanu tana modaṭi naṭin̄cina vāhanaṁ ādhāraṅgā iṇṭi pērugā mārē avakāśaṁ lēdu., extra_data=\"{'translat...\")\n",
            "pashto\n",
            "Translated(src=en, dest=ps, text=د دریو عالي پرنسپل سندرغاړو سره ، یو ځوان او ښه ښکلا ډیوا او ټایر او بډایه ښکلي موقعیتونه ، دا کافي دي چې تاسو ته دا هیله درکړي چې جاکوټ یوازې په کافي اندازه یوازې پاتې شوی و او پرته له دې ټولو تحلیلونو پرته د اوپیرا فلمونه جوړ کړي., pronunciation=With three excellent principal singers , a youthful and good-looking diva and tenor and richly handsome locations , it 's enough to make you wish Jacquot had left well enough alone and just filmed the opera without all these distortions of perspective , extra_data=\"{'translat...\")\n",
            "slovak\n",
            "Translated(src=en, dest=sk, text=To, čo mohlo byť ostrým malým chladičom o desivej zvodnosti novej technológie, stráca vieru vo svoju vlastnú životaschopnosť a podľahne bezradnému prebytku špeciálnych efektov, pronunciation=What could have been a pointed little chiller about the frightening seductiveness of new technology loses faith in its own viability and succumbs to joyless special-effects excess , extra_data=\"{'translat...\")\n",
            "slovenian\n",
            "Translated(src=en, dest=sl, text=Ta plen o mladih napeh v Brooklynu po dveh letih ni na prodaj, da bi izkoristil priljubljenost Vin Diesel, Seth Green in Barry Pepper, pronunciation=This heist flick about young Brooklyn hoods is off the shelf after two years to capitalize on the popularity of Vin Diesel , Seth Green and Barry Pepper , extra_data=\"{'translat...\")\n",
            "kannada\n",
            "Translated(src=en, dest=kn, text=ಆದರೆ, ಇಲ್ಲ, ನಾವು ಇನ್ನೊಂದು ದೃಶ್ಯವನ್ನು ಪಡೆಯುತ್ತೇವೆ, ಮತ್ತು ನಂತರ ಮತ್ತೊಂದು ದೃಶ್ಯವನ್ನು ಪಡೆಯುತ್ತೇವೆ, pronunciation=Ādare, illa, nāvu innondu dr̥śyavannu paḍeyuttēve, mattu nantara mattondu dr̥śyavannu paḍeyuttēve, extra_data=\"{'translat...\")\n",
            "kannada\n",
            "Translated(src=en, dest=kn, text=ಹೇಳುವಷ್ಟು ನೀರಸವಾಗಿರಬಹುದು - ಮತ್ತು ಕೆಲವೊಮ್ಮೆ, ಕಿಟ್‌ಷ್‌ನೊಂದಿಗೆ ಚೆಲ್ಲಾಟವಾಡುವುದಕ್ಕಿಂತ ಆಲ್ ಮೈ ಲವ್ಡ್ ಒನ್ಸ್ ಹೆಚ್ಚು - ಕಥೆಯು ಗಮನವನ್ನು ನೀಡುತ್ತದೆ, pronunciation=Hēḷuvaṣṭu nīrasavāgirabahudu - mattu kelavom'me, kiṭ‌ṣ‌nondige cellāṭavāḍuvudakkinta āl mai lavḍ ons heccu - katheyu gamanavannu nīḍuttade, extra_data=\"{'translat...\")\n",
            "javanese\n",
            "Translated(src=en, dest=jw, text=utawa bisa uga, \"Kepiye sampeyan bakal ngrasakake nyuworo 88 menit saka Rock kanthi aksi sing ora bisa diluncurake kanthi tembakan slo-mo lan pecah kaca acak? '', pronunciation=[[]], extra_data=\"{'translat...\")\n",
            "french\n",
            "Translated(src=en, dest=fr, text=Étant l'arrière-petit-fils de l'auteur Wells, vous penseriez que le cinéaste Simon Wells aurait plus de respect pour le matériel, pronunciation=Étant l'arrière-petit-fils de l'auteur Wells, vous penseriez que le cinéaste Simon Wells aurait plus de respect pour le matériel, extra_data=\"{'translat...\")\n",
            "french\n",
            "Translated(src=en, dest=fr, text=C'est un film d'espionnage intelligent, solide et chargé cinétiquement digne de quelques heures d'été et d'un seau de pop-corn, pronunciation=C'est un film d'espionnage intelligent, solide et chargé cinétiquement digne de quelques heures d'été et d'un seau de pop-corn, extra_data=\"{'translat...\")\n",
            "telugu\n",
            "Translated(src=en, dest=te, text=మీకు తేలికపాటి తలనొప్పినిచ్చే లేదా మిమ్మల్ని ఉల్లాసపరిచే రకమైన నాడీ చిత్రం, pronunciation=Mīku tēlikapāṭi talanoppiniccē lēdā mim'malni ullāsaparicē rakamaina nāḍī citraṁ, extra_data=\"{'translat...\")\n",
            "corsican\n",
            "Translated(src=en, dest=co, text=Una evucazione affascinante di a qualità chì mantene a Dickens perenne: l'apertura esuberante cù a quale esprime e nostre emozioni più basiche, pronunciation=A beguiling evocation of the quality that keeps Dickens evergreen : the exuberant openness with which he expresses our most basic emotions , extra_data=\"{'translat...\")\n",
            "chinese (traditional)\n",
            "Translated(src=en, dest=zh-tw, text=讓動畫倒退30年，音樂劇倒退40年，猶太教倒退至少50年, pronunciation=Ràng dònghuà dàotuì 30 nián, yīnyuè jù dàotuì 40 nián, yóutàijiào dàotuì zhìshǎo 50 nián, extra_data=\"{'translat...\")\n",
            "khmer\n",
            "Translated(src=en, dest=km, text=ដំណើររបស់អាណាមិនមែនជាការរកឃើញដោយខ្លួនឯងទេពីព្រោះនាងមានផាសុកភាពគ្រប់គ្រាន់នៅក្នុងស្បែករបស់នាងផ្ទាល់ដែលមានមោទនភាពចំពោះរូបវិទ្យា Rubenesque របស់នាង។, pronunciation=damnaer robsa ana minmen chea kar rk kheunh daoyokhluoneng te piproh neang mean phasokpheap krobkrean nowknong sbek robsa neang phtal del mean motonpheap champoh roubvitya Rubenesque  robsa neang ., extra_data=\"{'translat...\")\n",
            "danish\n",
            "Translated(src=en, dest=da, text=Hvad forældre vil mistanke om, er at de ser en 76-minutters reklame, pronunciation=What parents will suspect is that they 're watching a 76-minute commercial , extra_data=\"{'translat...\")\n",
            "lithuanian\n",
            "Translated(src=en, dest=lt, text=Filmas patiks „Discovery Channel“ gerbėjams ir tikrai praplės mūsų, reginčių žemyną pro rožinius akinius, perspektyvą., pronunciation=The film will appeal to Discovery Channel fans and will surely widen the perspective of those of us who see the continent through rose-colored glasses , extra_data=\"{'translat...\")\n",
            "hausa\n",
            "Translated(src=en, dest=ha, text=Aramar, babban buri da cimma buri, Yara na Centarnin sun ɗauki aikin Kurys zuwa wani sabon matakin, pronunciation=In scope , ambition and accomplishment , Children of the Century  takes Kurys ' career to a whole new level , extra_data=\"{'translat...\")\n",
            "chinese (simplified)\n",
            "Translated(src=en, dest=zh-cn, text=艺术的本能也令人感到吉祥和大胆，这促使像史蒂文·斯皮尔伯格这样的以多数为导向的导演跟随AI提出这一具有挑战性的报告，从而使多数人不安, pronunciation=Yìshù de běnnéng yě lìng rén gǎndào jíxiáng hé dàdǎn, zhè cùshǐ xiàng shǐ dì wén·sī pí'ěr bó gé zhèyàng de yǐ duōshù wéi dǎoxiàng de dǎoyǎn gēnsuí AI tíchū zhè yī jùyǒu tiǎozhàn xìng de bàogào, cóng'ér shǐ duōshù rén bù'ān, extra_data=\"{'translat...\")\n",
            "arabic\n",
            "Translated(src=en, dest=ar, text=في حين أن التلميحات المتكررة للمعلمين والدوشاس ستذهل بعض الغربيين على أنها تقترب من خطوط عريضة من الفطرة السليمة تظهر بوضوح لا يرقى إليه الشك, pronunciation=fy hyn 'ana altalmihat almutakarirat lilmuealimin walduwshas satadhhal bed algharbiiyn ealaa 'anaha taqtarib min khutut earidat min alfutrat alsalimat tazhar biwuduh la yarqaa 'iilayh alshaku, extra_data=\"{'translat...\")\n",
            "sundanese\n",
            "Translated(src=en, dest=su, text=Éta sacara intensif pribadi sareng - henteu sapertos Quills - jelas nunjukkeun urang watek jaman, pronunciation=It is intensely personal and yet -- unlike Quills -- deftly shows us the temper of the times , extra_data=\"{'translat...\")\n",
            "kannada\n",
            "Translated(src=en, dest=kn, text=ಬೆರಗುಗೊಳಿಸುವ ಮನರಂಜನೆಯ ವೆಬ್ ಅನ್ನು ತಿರುಗಿಸುವುದು ಅದನ್ನು ಅತಿಯಾಗಿ ಮೀರಿಸಬಹುದು, ಆದರೆ `` ಸ್ಪೈಡರ್ ಮ್ಯಾನ್ '' ಖಂಡಿತವಾಗಿಯೂ ಸರಕುಗಳನ್ನು ನೀಡುತ್ತದೆ, pronunciation=Beragugoḷisuva manaran̄janeya veb annu tirugisuvudu adannu atiyāgi mīrisabahudu, ādare ``spaiḍar myān'' khaṇḍitavāgiyū sarakugaḷannu nīḍuttade, extra_data=\"{'translat...\")\n",
            "georgian\n",
            "Translated(src=en, dest=ka, text=არც თუ ისე შორეულ მომავალში ფილმები, როგორიცაა Ghost Ship, გამოყენებული იქნება როგორც ტკივილგამაყუჩებელი ბალზამი ზედმეტად სტიმულირებული გონებისთვის, pronunciation=arts tu ise shoreul momavalshi pilmebi, rogoritsaa Ghost Ship, gamoq’enebuli ikneba rogorts t’k’ivilgamaq’uchebeli balzami zedmet’ad st’imulirebuli gonebistvis, extra_data=\"{'translat...\")\n",
            "yoruba\n",
            "Translated(src=en, dest=yo, text=Ifojusi fiimu naa ni idaniloju iboju iboju rẹ, mejeeji fun ijiroro rhapsodic ti o fo loju iwe naa, ati fun awọn idasilẹ ohun kikọ ti o ṣe iranti, pronunciation=The film 's highlight is definitely its screenplay , both for the rhapsodic dialogue that jumps off the page , and for the memorable character creations , extra_data=\"{'translat...\")\n",
            "slovak\n",
            "Translated(src=en, dest=sk, text=Expozícia Pan Nalin je krásna a tajomná a nasledujúce rozhovory s praktikmi tejto staroindickej praxe sú rovnako jemné a záhadné., pronunciation=Pan Nalin 's exposition is beautiful and mysterious , and the interviews that follow , with the practitioners of this ancient Indian practice , are as subtle and as enigmatic , extra_data=\"{'translat...\")\n",
            "korean\n",
            "Translated(src=en, dest=ko, text=J Lo는이 영화에서 한 가지를 완벽하게 보여 주지만 홀리데이 박스 오피스 파이에서 그녀의 몫을 얻게 될 것입니다. 그녀는 예쁜 여자이지만 일하는 소녀가 아닙니다., pronunciation=J Loneun-i yeonghwa-eseo han gajileul wanbyeoghage boyeo jujiman hollidei bagseu opiseu paieseo geunyeoui mogs-eul eodge doel geos-ibnida. geunyeoneun yeppeun yeojaijiman ilhaneun sonyeoga anibnida., extra_data=\"{'translat...\")\n",
            "igbo\n",
            "Translated(src=en, dest=ig, text=Ọ bụ ezie na ọkụ nke agha Hart anaghị atọ ọchị, ọ ka bụ ihe kwesịrị ekwesị na mgbakwunye na-eto eto nke ụtụ Ryan na-echekwa post-Saving Private Ryan, pronunciation=While the stoically delivered hokum of Hart 's War is never fun , it 's still a worthy addition to the growing canon of post-Saving Private Ryan tributes to the greatest generation , extra_data=\"{'translat...\")\n",
            "corsican\n",
            "Translated(src=en, dest=co, text=Ùn duverebbe micca esse permessu di aduprà a parolla \"novu\" in u so tittulu, perchè ùn ci hè micca un caratteru originale, una situazione o una burla in tuttu u filmu, pronunciation=Should n't have been allowed to use the word `` new '' in its title , because there 's not an original character , siuation or joke in the entire movie , extra_data=\"{'translat...\")\n",
            "luxembourgish\n",
            "Translated(src=en, dest=lb, text=Näischt iwwer de Film - mat der méiglecher Ausnam vun der Broscht vum Elizabeth Hurley - ass authentesch, pronunciation=Nothing about the film -- with the possible exception of Elizabeth Hurley 's breasts -- is authentic , extra_data=\"{'translat...\")\n",
            "galician\n",
            "Translated(src=en, dest=gl, text=O bo que poida ser esta película depende de se cre que a impactante conclusión é un mergullo demasiado ou non, pronunciation=How good this film might be , depends if you believe that the shocking conclusion is too much of a plunge or not , extra_data=\"{'translat...\")\n",
            "chichewa\n",
            "Translated(src=en, dest=ny, text=Sichikwanira kwambiri kuseka kwake kapena malingaliro ake amtundu kuti aziwoneka ngati osakumbukika kapena ngakhale zoseketsa, pronunciation=Does not go far enough in its humor or stock ideas to stand out as particularly memorable or even all that funny , extra_data=\"{'translat...\")\n",
            "cebuano\n",
            "Translated(src=en, dest=ceb, text=Nagmalampuson lang tungod kay ang Bullock ug Grant gihimo aron mabahin ang screen sa pilak, pronunciation=Succeeds only because Bullock and Grant were made to share the silver screen , extra_data=\"{'translat...\")\n",
            "romanian\n",
            "Translated(src=en, dest=ro, text=Sayles face o declarație despre incapacitatea viselor și aspirațiilor de a continua în generația următoare, pronunciation=Sayles is making a statement about the inability of dreams and aspirations to carry forward into the next generation , extra_data=\"{'translat...\")\n",
            "ukrainian\n",
            "Translated(src=en, dest=uk, text=Неквапливий темп фільму насправді є однією з його сильних сторін, pronunciation=Nekvaplyvyy temp filʹmu naspravdi ye odniyeyu z yoho sylʹnykh storin, extra_data=\"{'translat...\")\n",
            "lithuanian\n",
            "Translated(src=en, dest=lt, text=Kadangi McConaughey yra zonoje, kurioje visiškai nėra ironijos, o Bale'as iš esmės sumažėja iki jautrių akių vokų plakimo, ekrane nepakanka intelekto, proto ar naujovių, kad pritrauktų ir išlaikytų vyresnę minią, pronunciation=With McConaughey in an entirely irony-free zone and Bale reduced mainly to batting his sensitive eyelids , there 's not enough intelligence , wit or innovation on the screen to attract and sustain an older crowd , extra_data=\"{'translat...\")\n",
            "belarusian\n",
            "Translated(src=en, dest=be, text=У мудрагелістай камедыі Сары Шугарман \"Вельмі Эні-Мэры\" ёсць моманты сапраўднага задавальнення, але недастатковыя для падтрымання фільма, pronunciation=U mudrahielistaj kamiedyi Sary Šuharman \"Vieĺmi Eni-Mery\" josć momanty sapraŭdnaha zadavaĺniennia, alie niedastatkovyja dlia padtrymannia fiĺma, extra_data=\"{'translat...\")\n",
            "nepali\n",
            "Translated(src=en, dest=ne, text=श्री डीड्स वास्तवमै कुनै फिल्म होइन यो अलि अनौंठो हास्यास्पद gags को एक ढीला संग्रह हो, आलस्य हास्य को बिखरी क्षण, pronunciation=Śrī ḍīḍsa vāstavamai kunai philma hō'ina yō ali anauṇṭhō hāsyāspada gags kō ēka ḍhīlā saṅgraha hō, ālasya hāsya kō bikharī kṣaṇa, extra_data=\"{'translat...\")\n",
            "nepali\n",
            "Translated(src=en, dest=ne, text=आयर अमेरिकी भारतीय स्पाइक ली बन्ने बाटोमा छन्, pronunciation=Āyara amērikī bhāratīya spā'ika lī bannē bāṭōmā chan, extra_data=\"{'translat...\")\n",
            "bosnian\n",
            "Translated(src=en, dest=bs, text=Korisna Euro-trash akcijska ekstravaganca, s pristojnim smislom za humor i mnoštvom stvari koje doživljavaju procvat - pištoljima, BMW-ima i primorskim dvorcima, pronunciation=A serviceable Euro-trash action extravaganza , with a decent sense of humor and plenty of things that go boom -- handguns , BMWs and seaside chateaus , extra_data=\"{'translat...\")\n",
            "urdu\n",
            "Translated(src=en, dest=ur, text=یہاں تک کہ جب میں نے بڑی دلچسپی سے دلچسپی برقرار رکھنے کی جدوجہد کی ، یا کم از کم ہوش میں ، میں اپنی پلکیں بہت زیادہ بھاری ہونے کا احساس کرسکتا ہوں, pronunciation=Even as I valiantly struggled to remain interested , or at least conscious , I could feel my eyelids  getting  very  heavy , extra_data=\"{'translat...\")\n",
            "polish\n",
            "Translated(src=en, dest=pl, text=Shankman  and screenwriter Karen Janszen bungle their way through the narrative as if it were a series of Bible parables and not an actual story , pronunciation=Shankman  and screenwriter Karen Janszen bungle their way through the narrative as if it were a series of Bible parables and not an actual story , extra_data=\"{'translat...\")\n",
            "arabic\n",
            "Translated(src=en, dest=ar, text=What ` Dumb and Dumber ' would have been without the vulgarity and with an intelligent , life-affirming script , pronunciation=What ` Dumb and Dumber ' would have been without the vulgarity and with an intelligent , life-affirming script , extra_data=\"{'translat...\")\n",
            "filipino\n",
            "Translated(src=en, dest=tl, text=There is n't nearly enough fun here , despite the presence of some appealing ingredients , pronunciation=There is n't nearly enough fun here , despite the presence of some appealing ingredients , extra_data=\"{'translat...\")\n",
            "khmer\n",
            "Translated(src=en, dest=km, text=The acting is just fine , but there 's not enough substance here to sustain interest for the full 90 minutes , especially with the weak payoff , pronunciation=The acting is just fine , but there 's not enough substance here to sustain interest for the full 90 minutes , especially with the weak payoff , extra_data=\"{'translat...\")\n",
            "basque\n",
            "Translated(src=en, dest=eu, text=Director Clare Kilner 's debut is never as daft as it should have been , pronunciation=Director Clare Kilner 's debut is never as daft as it should have been , extra_data=\"{'translat...\")\n",
            "albanian\n",
            "Translated(src=en, dest=sq, text=You might say Tykwer has done all that Heaven allows , if you wanted to make as anti-Kieslowski a pun as possible , pronunciation=You might say Tykwer has done all that Heaven allows , if you wanted to make as anti-Kieslowski a pun as possible , extra_data=\"{'translat...\")\n",
            "hmong\n",
            "Translated(src=en, dest=hmn, text=More of the same old garbage Hollywood has been trying to pass off as acceptable teen entertainment for some time now , pronunciation=More of the same old garbage Hollywood has been trying to pass off as acceptable teen entertainment for some time now , extra_data=\"{'translat...\")\n",
            "kazakh\n",
            "Translated(src=en, dest=kk, text=There are times when A Rumor of Angels plays like an extended episode of Touched by an Angel -- a little too much dancing , a few too many weeping scenes -- but I liked its heart and its spirit , pronunciation=There are times when A Rumor of Angels plays like an extended episode of Touched by an Angel -- a little too much dancing , a few too many weeping scenes -- but I liked its heart and its spirit , extra_data=\"{'translat...\")\n",
            "bengali\n",
            "Translated(src=en, dest=bn, text=This is the first film I 've ever seen that had no obvious directing involved , pronunciation=This is the first film I 've ever seen that had no obvious directing involved , extra_data=\"{'translat...\")\n",
            "georgian\n",
            "Translated(src=en, dest=ka, text=Seems based on ugly ideas instead of ugly behavior , as Happiness was  Hence , Storytelling is far more appealing , pronunciation=Seems based on ugly ideas instead of ugly behavior , as Happiness was  Hence , Storytelling is far more appealing , extra_data=\"{'translat...\")\n",
            "khmer\n",
            "Translated(src=en, dest=km, text=Finally coming down off of Miramax 's deep shelves after a couple of aborted attempts , Waking Up in Reno makes a strong case for letting sleeping dogs lie , pronunciation=Finally coming down off of Miramax 's deep shelves after a couple of aborted attempts , Waking Up in Reno makes a strong case for letting sleeping dogs lie , extra_data=\"{'translat...\")\n",
            "greek\n",
            "Translated(src=en, dest=el, text=But it has an ambition to say something about its subjects , but not a willingness , pronunciation=But it has an ambition to say something about its subjects , but not a willingness , extra_data=\"{'translat...\")\n",
            "esperanto\n",
            "Translated(src=en, dest=eo, text=Go for La Salle 's performance , and make do as best you can with a stuttering script , pronunciation=Go for La Salle 's performance , and make do as best you can with a stuttering script , extra_data=\"{'translat...\")\n",
            "javanese\n",
            "Translated(src=en, dest=jw, text=It 's mildly interesting to ponder the peculiar American style of justice that plays out here , but it 's so muddled and derivative that few will bother thinking it all through , pronunciation=It 's mildly interesting to ponder the peculiar American style of justice that plays out here , but it 's so muddled and derivative that few will bother thinking it all through , extra_data=\"{'translat...\")\n",
            "norwegian\n",
            "Translated(src=en, dest=no, text=I am sorry that I was unable to get the full brunt of the comedy , pronunciation=I am sorry that I was unable to get the full brunt of the comedy , extra_data=\"{'translat...\")\n",
            "hebrew\n",
            "Translated(src=en, dest=he, text=I enjoyed the movie in a superficial way , while never sure what its purpose was , pronunciation=I enjoyed the movie in a superficial way , while never sure what its purpose was , extra_data=\"{'translat...\")\n",
            "turkish\n",
            "Translated(src=en, dest=tr, text=What 's needed so badly but what is virtually absent here is either a saving dark humor or the feel of poetic tragedy , pronunciation=What 's needed so badly but what is virtually absent here is either a saving dark humor or the feel of poetic tragedy , extra_data=\"{'translat...\")\n",
            "bulgarian\n",
            "Translated(src=en, dest=bg, text=A sterling film - a cross between Boys Do n't Cry , Deliverance , and Ode to Billy Joe - lies somewhere in the story of Matthew Shepard , but that film is yet to be made , pronunciation=A sterling film - a cross between Boys Do n't Cry , Deliverance , and Ode to Billy Joe - lies somewhere in the story of Matthew Shepard , but that film is yet to be made , extra_data=\"{'translat...\")\n",
            "bengali\n",
            "Translated(src=en, dest=bn, text= pays tribute to heroes the way Julia Roberts hands out awards -- with phony humility barely camouflaging grotesque narcissism , pronunciation= pays tribute to heroes the way Julia Roberts hands out awards -- with phony humility barely camouflaging grotesque narcissism , extra_data=\"{'translat...\")\n",
            "serbian\n",
            "Translated(src=en, dest=sr, text=But it also comes with the laziness and arrogance of a thing that already knows it 's won , pronunciation=But it also comes with the laziness and arrogance of a thing that already knows it 's won , extra_data=\"{'translat...\")\n",
            "khmer\n",
            "Translated(src=en, dest=km, text=Those who are not acquainted with the author 's work , on the other hand , may fall fast asleep , pronunciation=Those who are not acquainted with the author 's work , on the other hand , may fall fast asleep , extra_data=\"{'translat...\")\n",
            "hebrew\n",
            "Translated(src=en, dest=iw, text=It 's like an all-star salute to Disney 's cheesy commercialism , pronunciation=It 's like an all-star salute to Disney 's cheesy commercialism , extra_data=\"{'translat...\")\n",
            "finnish\n",
            "Translated(src=en, dest=fi, text=Parker can not sustain the buoyant energy level of the film 's city beginnings into its country conclusion ', pronunciation=Parker can not sustain the buoyant energy level of the film 's city beginnings into its country conclusion ', extra_data=\"{'translat...\")\n",
            "sesotho\n",
            "Translated(src=en, dest=st, text=Nothing more than a stifling morality tale dressed up in peekaboo clothing , pronunciation=Nothing more than a stifling morality tale dressed up in peekaboo clothing , extra_data=\"{'translat...\")\n",
            "tamil\n",
            "Translated(src=en, dest=ta, text=The creaking , rusty ship makes a fine backdrop , but the ghosts ' haunting is routine , pronunciation=The creaking , rusty ship makes a fine backdrop , but the ghosts ' haunting is routine , extra_data=\"{'translat...\")\n",
            "telugu\n",
            "Translated(src=en, dest=te, text=This cuddly sequel to the 1999 hit is a little more visually polished , a little funnier , and a little more madcap , pronunciation=This cuddly sequel to the 1999 hit is a little more visually polished , a little funnier , and a little more madcap , extra_data=\"{'translat...\")\n",
            "russian\n",
            "Translated(src=en, dest=ru, text=But even then , I 'd recommend waiting for DVD and just skipping straight to her scenes , pronunciation=But even then , I 'd recommend waiting for DVD and just skipping straight to her scenes , extra_data=\"{'translat...\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "iWrj8COv1nvm",
        "outputId": "e1f6bbe7-b9f1-4457-a2a2-2448acb9dd7b"
      },
      "source": [
        "print(for_translate_df.shape)\r\n",
        "for_translate_df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "      <th>label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7755</th>\n",
              "      <td>8121</td>\n",
              "      <td>It 's often faintly amusing , but the problems of the characters never become important to us , and the story never takes hold</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>negative</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9397</th>\n",
              "      <td>9845</td>\n",
              "      <td>Aloof and lacks any real raw emotion , which is fatal for a film that relies on personal relationships</td>\n",
              "      <td>0.19444</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>1527</td>\n",
              "      <td>While it regards 1967 as the key turning point of the 20th century , and returns again and again to images of dissidents in the streets , it 's alarmingly current</td>\n",
              "      <td>0.43056</td>\n",
              "      <td>neutral</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3601</th>\n",
              "      <td>3765</td>\n",
              "      <td>It 's incredible the number of stories the Holocaust has generated</td>\n",
              "      <td>0.66667</td>\n",
              "      <td>positive</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6806</th>\n",
              "      <td>7120</td>\n",
              "      <td>It is most of the things Costner movies are known for ; it 's sanctimonious , self-righteous and so eager to earn our love that you want to slap it</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>negative</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... words\n",
              "7755            8121  ...    24\n",
              "9397            9845  ...    19\n",
              "1466            1527  ...    31\n",
              "3601            3765  ...    11\n",
              "6806            7120  ...    30\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "xqNPGzTU2H4I",
        "outputId": "bbd0edf9-1351-4930-e89c-6f6bca9bb664"
      },
      "source": [
        "print(for_translate_df1.shape)\r\n",
        "for_translate_df1.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>sentiment_value</th>\n",
              "      <th>label</th>\n",
              "      <th>words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7755</th>\n",
              "      <td>8121</td>\n",
              "      <td>It's often amusing, but the characters' problems never become important to us, and the story never catches on.</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>negative</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9397</th>\n",
              "      <td>9845</td>\n",
              "      <td>Lately and there is no real raw emotion, which is dangerous for a film that relies on personal relationships</td>\n",
              "      <td>0.19444</td>\n",
              "      <td>negative</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>1527</td>\n",
              "      <td>Considering 1967 as a major turning point in the 20th century, when it comes back to the images of dissidents on the streets, it is a dangerous current.</td>\n",
              "      <td>0.43056</td>\n",
              "      <td>neutral</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3601</th>\n",
              "      <td>3765</td>\n",
              "      <td>These are the amazing numbers that the Holocaust created</td>\n",
              "      <td>0.66667</td>\n",
              "      <td>positive</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6806</th>\n",
              "      <td>7120</td>\n",
              "      <td>That’s most of the things that Costner movies are known for; its sacred, selfish and so eager to earn our love that you want to beat it</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>negative</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... words\n",
              "7755            8121  ...    24\n",
              "9397            9845  ...    19\n",
              "1466            1527  ...    31\n",
              "3601            3765  ...    11\n",
              "6806            7120  ...    30\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6suhmPk76zy",
        "outputId": "6b6dce37-597e-4b4b-cfce-92a6d1fdec8b"
      },
      "source": [
        "for_random_deletion_df= train_df[train_df.words>10].sample(frac=0.5,random_state=10)\r\n",
        "print(for_random_deletion_df.shape)\r\n",
        "for_random_deletion_df1 = for_random_deletion_df.copy()\r\n",
        "for_random_deletion_df1['sentence'] = for_random_deletion_df1.sentence.str.split().apply(random_deletion).apply(' '.join)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3040, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laM-KmhkCkYW",
        "outputId": "1ae83b4b-bb40-464f-fbf7-bf77d553b9ca"
      },
      "source": [
        "for_random_deletion_df1.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3040, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpuTfffUClmQ",
        "outputId": "4ee46f7c-b725-4d03-c046-000ad0182f20"
      },
      "source": [
        "for_random_swap_df= train_df[train_df.words>10].sample(frac=0.5,random_state=16)\r\n",
        "print(for_random_swap_df.shape)\r\n",
        "for_random_swap_df1 = for_random_swap_df.copy()\r\n",
        "for_random_swap_df1['sentence'] = for_random_swap_df1.sentence.str.split().apply(random_swap).apply(' '.join)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3040, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBuesusF-Zw"
      },
      "source": [
        "augmented_train_df = pd.concat([train_df,for_random_deletion_df1,for_random_swap_df1,for_translate_df1], axis=0).reset_index(drop=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fod9OFoNGpAK"
      },
      "source": [
        "augmented_train_df = augmented_train_df[['sentence','label']]\r\n",
        "test_df = test_df[['sentence','label']].reset_index(drop=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "pYb9J5oaGTf0",
        "outputId": "1c6142d4-e687-4678-eede-141947496121"
      },
      "source": [
        "augmented_train_df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>There 's an audience for it , but it could have been funnier and more innocent</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>For those who pride themselves on sophisticated , discerning taste , this might not seem like the proper cup of tea , however it is almost guaranteed that even the stuffiest cinema goers will laugh their \\*\\*\\* off for an hour-and-a-half</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A gripping documentary that reveals how deep the antagonism lies in war-torn Jerusalem</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Those moviegoers who would automatically bypass a hip-hop documentary should give `` Scratch '' a second look</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The characters are never more than sketches  which leaves any true emotional connection or identification frustratingly out of reach</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                         sentence     label\n",
              "0                                                                                                                                                                 There 's an audience for it , but it could have been funnier and more innocent   negative\n",
              "1  For those who pride themselves on sophisticated , discerning taste , this might not seem like the proper cup of tea , however it is almost guaranteed that even the stuffiest cinema goers will laugh their \\*\\*\\* off for an hour-and-a-half   positive\n",
              "2                                                                                                                                                         A gripping documentary that reveals how deep the antagonism lies in war-torn Jerusalem   positive\n",
              "3                                                                                                                                  Those moviegoers who would automatically bypass a hip-hop documentary should give `` Scratch '' a second look   positive\n",
              "4                                                                                                           The characters are never more than sketches  which leaves any true emotional connection or identification frustratingly out of reach   negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Lkfy2ZaIGfhK",
        "outputId": "2389305a-4bbe-45b3-c414-dd01722349cb"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Offers that rare combination of entertainment and education</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is a film well worth seeing , talking and singing heads and all</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An utterly compelling ` who wrote it ' in which the reputation of the most famous author who ever lived comes into question</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Scores a few points for doing what it does with a dedicated and good-hearted professionalism</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                       sentence     label\n",
              "0                                                                  Offers that rare combination of entertainment and education   positive\n",
              "1                   Perhaps no picture ever made has more literally showed that the road to hell is paved with good intentions   positive\n",
              "2                                                         This is a film well worth seeing , talking and singing heads and all   positive\n",
              "3  An utterly compelling ` who wrote it ' in which the reputation of the most famous author who ever lived comes into question   positive\n",
              "4                                 Scores a few points for doing what it does with a dedicated and good-hearted professionalism   positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9T_HDvNtGkd9",
        "outputId": "2333f3bf-4b4c-4a78-ff25-4f4c6f3180b2"
      },
      "source": [
        "augmented_train_df.label.value_counts()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    5948\n",
              "negative    5498\n",
              "neutral     2634\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3ibk3HpJdF0"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\r\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc7Weme-JoAL"
      },
      "source": [
        "fields = [('sentence', Sentence),('label',Label)]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56e0KQ2TJ1r3"
      },
      "source": [
        "train_example = [data.Example.fromlist([augmented_train_df.sentence[i],augmented_train_df.label[i]], fields) for i in range(augmented_train_df.shape[0])] \r\n",
        "\r\n",
        "test_example = [data.Example.fromlist([test_df.sentence[i],test_df.label[i]], fields) for i in range(test_df.shape[0])]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSQ92OPxLFCu"
      },
      "source": [
        "train_data = data.Dataset(train_example, fields)\r\n",
        "\r\n",
        "test_data = data.Dataset(test_example, fields)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41S8y8BuMOX6",
        "outputId": "ea1839d0-99a9-4a43-c2fa-d255d4031888"
      },
      "source": [
        "(len(train_data), len(test_data))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14080, 3386)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU4KxBvuMTb5",
        "outputId": "005e3316-dcc6-4068-b8a9-d12fefd08af5"
      },
      "source": [
        "vars(train_data.examples[2000])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'negative',\n",
              " 'sentence': ['The',\n",
              "  'big',\n",
              "  '-',\n",
              "  'screen',\n",
              "  'Scooby',\n",
              "  'makes',\n",
              "  'the',\n",
              "  'silly',\n",
              "  'original',\n",
              "  'cartoon',\n",
              "  'seem',\n",
              "  'smart',\n",
              "  'and',\n",
              "  'well',\n",
              "  '-',\n",
              "  'crafted',\n",
              "  'in',\n",
              "  'comparison']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVhxt5EaMgz8"
      },
      "source": [
        "Sentence.build_vocab(train_data, max_size = 7000)\r\n",
        "Label.build_vocab(train_data)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0OWd6enM4Ko",
        "outputId": "07fa4320-aa1d-4bbb-84a4-16ea063c1b64"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\r\n",
        "print('Size of label vocab : ', len(Label.vocab))\r\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\r\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  7002\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [(',', 11329), ('the', 9713), ('a', 7010), ('of', 6960), ('and', 6878), ('to', 4891), ('-', 4267), ('is', 3990), (\"'s\", 3838), ('that', 2978)]\n",
            "Labels :  defaultdict(<function _default_unk_index at 0x7fbf4c721ea0>, {'positive': 0, 'negative': 1, 'neutral': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6_MWN7M_tv"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okntOKNENOkl"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train_data, test_data), batch_size = 32, \r\n",
        "                                                            sort_key = lambda x: len(x.sentence),\r\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFCqFPfCNV1H"
      },
      "source": [
        "import os, pickle\r\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \r\n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB4pNsLbNa38"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "class classifier(nn.Module):\r\n",
        "    \r\n",
        "    # Define all the layers used in model\r\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\r\n",
        "        \r\n",
        "        super().__init__()          \r\n",
        "        \r\n",
        "        # Embedding layer\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\r\n",
        "        \r\n",
        "        # LSTM layer\r\n",
        "        self.encoder = nn.LSTM(embedding_dim, \r\n",
        "                           hidden_dim, \r\n",
        "                           num_layers=n_layers, \r\n",
        "                           dropout=dropout,\r\n",
        "                           batch_first=True)\r\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\r\n",
        "        # try bidirectional and compare their performances\r\n",
        "        \r\n",
        "        # Dense layer\r\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\r\n",
        "        \r\n",
        "    def forward(self, text, text_lengths):\r\n",
        "        \r\n",
        "        # text = [batch size, sent_length]\r\n",
        "        embedded = self.embedding(text)\r\n",
        "        # embedded = [batch size, sent_len, emb dim]\r\n",
        "      \r\n",
        "        # packed sequence\r\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\r\n",
        "        \r\n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\r\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\r\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\r\n",
        "    \r\n",
        "        # Hidden = [batch size, hid dim * num directions]\r\n",
        "        dense_outputs = self.fc(hidden)   \r\n",
        "        \r\n",
        "        # Final activation function softmax\r\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\r\n",
        "            \r\n",
        "        return output"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CK5Yvfr3NoJu"
      },
      "source": [
        "# Define hyperparameters\r\n",
        "size_of_vocab = len(Sentence.vocab)\r\n",
        "embedding_dim = 300\r\n",
        "num_hidden_nodes = 100\r\n",
        "num_output_nodes = 3\r\n",
        "num_layers = 2\r\n",
        "dropout = 0.3\r\n",
        "\r\n",
        "# Instantiate the model\r\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XeWvtqqLNtAv",
        "outputId": "5188810d-6942-40bd-9626-e8e582cc8650"
      },
      "source": [
        "print(model)\r\n",
        "\r\n",
        "#No. of trianable parameters\r\n",
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "    \r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(7002, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.3)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 2,342,503 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U7HpU7lNxUu"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "\r\n",
        "# define optimizer and loss\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "# define metric\r\n",
        "def binary_accuracy(preds, y):\r\n",
        "    #round predictions to the closest integer\r\n",
        "    _, predictions = torch.max(preds, 1)\r\n",
        "    \r\n",
        "    correct = (predictions == y).float() \r\n",
        "    acc = correct.sum() / len(correct)\r\n",
        "    return acc\r\n",
        "    \r\n",
        "# push to cuda if available\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10WeBvUNOC5G"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\r\n",
        "    \r\n",
        "    # initialize every epoch \r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "    \r\n",
        "    # set the model in training phase\r\n",
        "    model.train()  \r\n",
        "    \r\n",
        "    for batch in iterator:\r\n",
        "        \r\n",
        "        # resets the gradients after every batch\r\n",
        "        optimizer.zero_grad()   \r\n",
        "        \r\n",
        "        # retrieve text and no. of words\r\n",
        "        sentence, sentence_lengths = batch.sentence   \r\n",
        "        \r\n",
        "        # convert to 1D tensor\r\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \r\n",
        "        \r\n",
        "        # compute the loss\r\n",
        "        loss = criterion(predictions, batch.label)        \r\n",
        "        \r\n",
        "        # compute the binary accuracy\r\n",
        "        acc = binary_accuracy(predictions, batch.label)   \r\n",
        "        \r\n",
        "        # backpropage the loss and compute the gradients\r\n",
        "        loss.backward()       \r\n",
        "        \r\n",
        "        # update the weights\r\n",
        "        optimizer.step()      \r\n",
        "        \r\n",
        "        # loss and accuracy\r\n",
        "        epoch_loss += loss.item()  \r\n",
        "        epoch_acc += acc.item()    \r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcKV5cNDOfpS"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    # initialize every epoch\r\n",
        "    epoch_loss = 0\r\n",
        "    epoch_acc = 0\r\n",
        "\r\n",
        "    # deactivating dropout layers\r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    # deactivates autograd\r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for batch in iterator:\r\n",
        "        \r\n",
        "            # retrieve text and no. of words\r\n",
        "            sentence, sentence_lengths = batch.sentence \r\n",
        "            \r\n",
        "            # convert to 1d tensor\r\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\r\n",
        "            \r\n",
        "            # compute loss and accuracy\r\n",
        "            loss = criterion(predictions, batch.label)\r\n",
        "            acc = binary_accuracy(predictions, batch.label)\r\n",
        "            \r\n",
        "            # keep track of loss and accuracy\r\n",
        "            epoch_loss += loss.item()\r\n",
        "            epoch_acc += acc.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eA3xpOUOrZT",
        "outputId": "1ae72d92-75f5-4d69-c8bd-9312cdaeee2e"
      },
      "source": [
        "N_EPOCHS = 10\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "     \r\n",
        "    # train the model\r\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\r\n",
        "    \r\n",
        "    # evaluate the model\r\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    # save the best model\r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\r\n",
        "    \r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.055 | Train Acc: 45.77%\n",
            "\t Val. Loss: 1.026 |  Val. Acc: 50.06% \n",
            "\n",
            "\tTrain Loss: 0.973 | Train Acc: 57.37%\n",
            "\t Val. Loss: 0.986 |  Val. Acc: 54.45% \n",
            "\n",
            "\tTrain Loss: 0.903 | Train Acc: 64.82%\n",
            "\t Val. Loss: 0.961 |  Val. Acc: 57.49% \n",
            "\n",
            "\tTrain Loss: 0.857 | Train Acc: 69.81%\n",
            "\t Val. Loss: 0.952 |  Val. Acc: 58.58% \n",
            "\n",
            "\tTrain Loss: 0.826 | Train Acc: 72.84%\n",
            "\t Val. Loss: 0.947 |  Val. Acc: 58.88% \n",
            "\n",
            "\tTrain Loss: 0.805 | Train Acc: 74.92%\n",
            "\t Val. Loss: 0.947 |  Val. Acc: 58.97% \n",
            "\n",
            "\tTrain Loss: 0.789 | Train Acc: 76.52%\n",
            "\t Val. Loss: 0.943 |  Val. Acc: 59.57% \n",
            "\n",
            "\tTrain Loss: 0.774 | Train Acc: 77.78%\n",
            "\t Val. Loss: 0.947 |  Val. Acc: 59.20% \n",
            "\n",
            "\tTrain Loss: 0.763 | Train Acc: 79.03%\n",
            "\t Val. Loss: 0.945 |  Val. Acc: 59.25% \n",
            "\n",
            "\tTrain Loss: 0.748 | Train Acc: 80.70%\n",
            "\t Val. Loss: 0.954 |  Val. Acc: 57.98% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPregljgOw2t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}